# 部署

## 上一篇总结

在上一篇文章中损失惨重——无论是精力还是时间。现在来总结一下。

### 机器配置选择

CPU：8 核；内存：32 GB。

### 版本对应

#### Python 3.9 + TensorFlow 2.12

首先是已经确定的版本：Python 3.9 + TensorFlow 2.12

- Python 3.9 是论文指定的版本。
- TensorFlow 2.12 是论文使用的 Tensorflow Addons 的要求，需要 2.12 ~ 2.15。

#### Driver >= 520.61.05 + cudatoolkit 11.8 + cuDNN 8.6

其次是关于 CUDA 的：显卡驱动、cudatoolkit 以及 cuDNN。

这三者之间版本有约束关系，但是并**不是唯一**的。

可参考官方网站。比较鸡贼的一点是中文网站的更新不够，只写到了 2.6 版本的对应。要去看英文网站。

- 英文：<https://www.tensorflow.org/install/source#gpu>

- 中文：<https://www.tensorflow.org/install/source?hl=zh-cn#gpu>

他这里推荐 Python 3.9 + TensorFlow 2.12 + cudatoolkit 11.8 + cuDNN 8.6。

那么接下来就应该考虑的是 NVIDIA 显卡驱动的版本。

参考官方网站：<https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html>

能支持 CUDA 11.8 的驱动版本要大于等于 520.61.05。

### 安装方法

首先要说明的是，安装方法与版本也有关系。总的来说，TensorFlow v2 搭配 CUDA 的安装比 v1 简单。我这里就只以当前情况来讲安装方法了。

#### CUDA 安装

##### 下载安装流

第一种是下载安装流：即在官网下载 CUDA 安装文件，同时安装驱动和 cudatoolkit；然后再手动下载解压 cuDNN 到指定的目录中。

官网下载 CUDA 安装文件：<https://developer.nvidia.com/cuda-toolkit-archive>，选择合适的版本，操作系统等。最后还要挑安装方式，这里我选择了 deb(network)。因为这不需要出现 TUI 来手动输入选择。

```shell
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda
```

安装完后使用 `nvidia-smi` 检查。

cuDNN 的下载安装方法无论如何都要账号登录才行。

- cuDNN 下载地址：<https://developer.nvidia.com/rdp/cudnn-archive>
- cuDNN 官网安装教程：<https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installlinux>

方法有 apt 安装方法和手动安装方法，但是都要先下载安装文件。

区别是：apt 安装不需要自己复制文件、设置软链接和设置环境变量。

apt 安装方法：

```shell
sudo dpkg -i cudnn-local-repo-ubuntu1804-8.6.0.163_1.0-1_amd64.deb
sudo cp /var/cudnn-local-repo-*/cudnn-local-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo yum install libcudnn8-8.6.0.*-1.cuda11.8
sudo yum install libcudnn8-devel-8.6.0.*-1.cuda11.8
sudo yum install libcudnn8-samples-8.6.0.*-1.cuda11.8
```

手动解压安装方法：

```shell
# 解压略
# 复制文件
sudo cp cuda/include/cudnn.h /usr/local/cuda-11.8/include
sudo cp cuda/lib64/libcudnn* /usr/local/cuda-11.8/lib64
sudo chmod a+r /usr/local/cuda-11.8/include/cudnn.h /usr/local/cuda-11.8/lib64/libcudnn*

# 软链接
cd /usr/local/cuda-11.8/lib64/
sudo rm -rf libcudnn.so libcudnn.so.8
sudo ln -s libcudnn.so.8.6.0 libcudnn.so.8
sudo ln -s libcudnn.so.8 libcudnn.so
sudo ldconfig -v
source /etc/profile

# .bashrc
echo 'export PATH=/usr/local/cuda-11.8/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

最后请使用官网上的验证方法：<https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#verify>

```shell
cp -r /usr/src/cudnn_samples_v8/ $HOME
cd  $HOME/cudnn_samples_v8/mnistCUDNN
make clean && make
./mnistCUDNN
```

成功则显示 `Test passed!`。

##### 使用 conda 安装

参考：<https://gretel.ai/blog/install-tensorflow-with-cuda-cdnn-and-gpu-support-in-4-easy-steps>

第一步是安装驱动。安装 525 版本。（因为 515 版本最高支持 CUDA 11.7）

```shell
sudo apt install ubuntu-drivers-common -y
ubuntu-drivers devices # 虽然只是查看的命令，但是很关键，详细见下面讲解
sudo apt install nvidia-driver-525 -y # 仅样例，实际版本需要查看 ubuntu-drivers devices
# sudo ubuntu-drivers autoinstall 如果 ubuntu-drivers devices 无 warning 则可使用
```

第二步是安装 conda。

```shell
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
source ~/.bashrc
```

第三步安装。

先使用 `conda search` 确定版本细节。

发现 cudnn 没有 8.6.0 版本，麻了，只有 8.9.2.26 版本。

```shell
conda create -n apenv python=3.9 -y
conda activate apenv
conda install -c conda-forge cudatoolkit=11.8 cudnn=8.9.2.26 -y
mkdir -p $CONDA_PREFIX/etc/conda/activate.d
echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/' > $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
```

##### 使用 docker 安装

仍然参考：<https://gretel.ai/blog/install-tensorflow-with-cuda-cdnn-and-gpu-support-in-4-easy-steps>

#### TensorFlow 安装验证

最后简单提一下 TensorFlow 安装：

pip 安装。

```shell
tensorflow==2.12
```

当然也有 conda 安装，只不过目前我没有研究。

---

验证方法：<https://www.tensorflow.org/install/pip#step-by-step_instructions>

```shell
python3 -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

#### 为何没有 pip 安装 CUDA

这个值得单独说一下。

根据官网的说法，这种方法只安装一些必要的运行时，**没有开发工具**。

官网链接：<https://docs.nvidia.com/cuda/cuda-quick-start-guide/index.html#pip-wheels-linux>

（把里面的 12 换成 11 就行）

这就导致如果人们不像通过安装程序来安装 CUDA 的话，就只能选择 conda 的方式安装。也侧面证明了 conda 的方便。

### 其他 tips

原样照抄：

- 下载代码和数据的方法。
- PYTHONPATH 的运行。

## 如何吸取经验教训

为了节约时间和精力，建议按照以下步骤来测试：

- 先更新包、安装显卡驱动。用 `nvidia-smi` 检查。
  - 后续实践：更新包的时候 apt 容易被其他进程占用，加入 `kill` 命令；安装完驱动必须要手动重启。不然后面无法正常调用 GPU。
- 设置 Git。
- 安装 conda。
- 下载代码，但不先下载数据集。（因为耗时过长，等确认完 TensorFlow 能被成功调用再下载也不迟）
- 安装依赖。（包括 cudatoolkit 和 cudnn）用上面提到的命令检查。
- 下载数据集。
- 运行 `run.sh` 中的测试。
- 执行 generate data。
- 执行 train model。并用 `nvidia-smi` 检查 GPU 显存使用情况。

---

下面是第一次进行测试的时候的命令，很幸运 conda 这次成功了。

```shell
# Git 设置
cat << EOF >> /etc/hosts
# github
140.82.113.4 github.com
199.232.69.194 github.global.ssl.fastly.net
EOF

# 更新 & 安装一些包 & 显卡驱动
pkill -9 apt # 保证不被占用
sudo apt update
sudo apt upgrade -y
sudo apt autoremove -y
sudo apt install ubuntu-drivers-common -y
sudo apt install nvidia-driver-525 -y
## 手动重启
## 检查
nvidia-smi

# 安装 conda
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
source ~/.bashrc

# 下载代码
git clone https://github.com/xuanhao44/SUAPCD.git
mv ~/SUAPCD/assessment_plan_modeling ~/assessment_plan_modeling
rm -rf SUAPCD

# 安装依赖
conda create -n apenv python=3.9 -y
conda activate apenv

pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/
pip install --upgrade pip
pip install -r assessment_plan_modeling/requirements.txt

conda install -c conda-forge cudatoolkit=11.8 cudnn=8.9.2.26 -y
mkdir -p $CONDA_PREFIX/etc/conda/activate.d
echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/' > $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
## 检查
python3 -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
conda deactivate

# 下载数据集
username=xxxxx
password=xxxxx
wget -r -N -c -np --user $username --password $password https://physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv.gz
gzip -d physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv.gz
mv physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv assessment_plan_modeling/data/notes.csv
rm -rf physionet.org

echo 0 | tee /sys/module/nvidia/drivers/pci:nvidia/*/numa_node
export TF_CPP_MIN_LOG_LEVEL=2

# run the tests! 重要
conda activate apenv
python3 -m assessment_plan_modeling.ap_parsing.ap_parsing_task_test
python3 -m assessment_plan_modeling.ap_parsing.ap_parsing_utils_test
python3 -m assessment_plan_modeling.ap_parsing.ap_problems_action_items_annotator_test
python3 -m assessment_plan_modeling.ap_parsing.augmentation_lib_test
python3 -m assessment_plan_modeling.ap_parsing.data_lib_test
python3 -m assessment_plan_modeling.ap_parsing.eval_lib_test
python3 -m assessment_plan_modeling.ap_parsing.tokenizer_lib_test
python3 -m assessment_plan_modeling.note_sectioning.note_section_test

# generate data
DATA_DIR="$HOME/assessment_plan_modeling/data"
TFRECORDS_PATH="${DATA_DIR}/ap_parsing_tf_examples/$(date +%Y%m%d)"
PYTHONPATH=$(pwd) python assessment_plan_modeling/ap_parsing/data_gen_main.py \
  --input_note_events="${DATA_DIR}/notes.csv" \
  --input_ratings="${DATA_DIR}/all_model_ratings.csv" \
  --output_path=${TFRECORDS_PATH} \
  --vocab_file="${DATA_DIR}/word_vocab_25K.txt" \
  --section_markers="assessment_plan_modeling/note_sectioning/data/mimic_note_section_markers.json" \
  --n_downsample=100 \
  --max_seq_length=2048

# train model
EXP_TYPE="ap_parsing"
CONFIG_DIR="assessment_plan_modeling/ap_parsing/configs"
MODEL_DIR="${DATA_DIR}/models/model_$(date +%Y%m%d-%H%M)"

TRAIN_DATA="${TFRECORDS_PATH}/train_rated_nonaugmented.tfrecord*"
VAL_DATA="${TFRECORDS_PATH}/val_set.tfrecord*"
PARAMS_OVERRIDE="task.use_crf=true"
PARAMS_OVERRIDE="${PARAMS_OVERRIDE},task.train_data.input_path='${TRAIN_DATA}'"
PARAMS_OVERRIDE="${PARAMS_OVERRIDE},task.validation_data.input_path='${VAL_DATA}'"
PARAMS_OVERRIDE="${PARAMS_OVERRIDE},trainer.train_steps=5000"

(time PYTHONPATH=$(pwd) python assessment_plan_modeling/ap_parsing/train.py \
  --experiment=${EXP_TYPE} \
  --config_file="${CONFIG_DIR}/base_ap_parsing_model_config.yaml" \
  --config_file="${CONFIG_DIR}/base_ap_parsing_task_config.yaml" \
  --params_override=${PARAMS_OVERRIDE} \
  --mode=train_and_eval \
  --model_dir=${MODEL_DIR} \
  --alsologtostderr) > ModelTrain_Out_$(date +%Y%m%d-%H%M).txt 2> ModelTrain_Error_$(date +%Y%m%d-%H%M).txt
```

---

后续可使用脚本：

执行下面命令。`<username>` 和 `<password>` 改成自己的。

```shell
# Git 设置
cat << EOF >> /etc/hosts
# github
140.82.113.4 github.com
199.232.69.194 github.global.ssl.fastly.net
EOF

# 更新 & 安装一些包 & 显卡驱动
pkill -9 apt # 保证不被占用
sudo apt update
sudo apt upgrade -y
sudo apt autoremove -y
sudo apt install ubuntu-drivers-common -y
sudo apt install nvidia-driver-525 -y
## 手动重启

# 脚本部署剩余的
wget https://raw.githubusercontent.com/xuanhao44/SUAPCD/main/pre.sh
chmod +x pre.sh
./pre.sh <username> <password>

# 进入 tmux 会话
## 开始数据生成和训练模型
tmux new -s train
pyenv activate apenv
wget https://raw.githubusercontent.com/xuanhao44/SUAPCD/main/do.sh
chmod +x do.sh
./do.sh
```
